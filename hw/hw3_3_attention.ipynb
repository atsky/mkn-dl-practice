{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JWosm81qkqfa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "af8a9e7196284adfb38e8d8bd2dadc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a97566da2a8b43d3a109fb08ff659898",
              "IPY_MODEL_edfaec824ae148f3b04521edd1e2313b",
              "IPY_MODEL_e8695208c42043aea6efe78793641791"
            ],
            "layout": "IPY_MODEL_23108a4b1c394dd7bf924a5dfdde7696"
          }
        },
        "a97566da2a8b43d3a109fb08ff659898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6467ecaf87804ce29383a0cf4eee1485",
            "placeholder": "​",
            "style": "IPY_MODEL_d64360b632b6468dadaf7e974aef5fea",
            "value": "  0%"
          }
        },
        "edfaec824ae148f3b04521edd1e2313b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e1332fb0fd3488ba036e8dee65b7ed2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_250331bf8de84ca382e3763ab5bf6da9",
            "value": 0
          }
        },
        "e8695208c42043aea6efe78793641791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ed39c3eb8748c1a6d7a839304513ba",
            "placeholder": "​",
            "style": "IPY_MODEL_de15d3d0035841de8e5b704c2dbf0587",
            "value": " 0/1 [20:07&lt;?, ?it/s]"
          }
        },
        "23108a4b1c394dd7bf924a5dfdde7696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6467ecaf87804ce29383a0cf4eee1485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64360b632b6468dadaf7e974aef5fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e1332fb0fd3488ba036e8dee65b7ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250331bf8de84ca382e3763ab5bf6da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48ed39c3eb8748c1a6d7a839304513ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de15d3d0035841de8e5b704c2dbf0587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "258ab1637d0d4fb4a8711c8d36535c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ae9585fad82471c88cf470ce16bb6d6",
              "IPY_MODEL_577a355427ff494a9c324ad9f280d84c",
              "IPY_MODEL_41bd8de5eab543d1a88344d53e39856f"
            ],
            "layout": "IPY_MODEL_9b9de2067e4d4604a819d738d0899e2e"
          }
        },
        "2ae9585fad82471c88cf470ce16bb6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de7603d3588b43309d15dbc8af5e9c4a",
            "placeholder": "​",
            "style": "IPY_MODEL_88425460fe344e868b79b1567c38535a",
            "value": " 15%"
          }
        },
        "577a355427ff494a9c324ad9f280d84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bda4a67e25d47e39d8964861998bff6",
            "max": 17133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3eb15e972b9b4749b8309ff246f159d5",
            "value": 2548
          }
        },
        "41bd8de5eab543d1a88344d53e39856f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e9e93aee32c4249888c2ab4e6bd8448",
            "placeholder": "​",
            "style": "IPY_MODEL_086defb81412400ea403639cb6b6a7e4",
            "value": " 2548/17133 [20:07&lt;1:50:56,  2.19it/s]"
          }
        },
        "9b9de2067e4d4604a819d738d0899e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de7603d3588b43309d15dbc8af5e9c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88425460fe344e868b79b1567c38535a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bda4a67e25d47e39d8964861998bff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eb15e972b9b4749b8309ff246f159d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e9e93aee32c4249888c2ab4e6bd8448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "086defb81412400ea403639cb6b6a7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В задании вам понадобится собрать генеративную модлель для языка и спользованием механизма внимания."
      ],
      "metadata": {
        "id": "cHJJv6Doqxdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet sentencepiece datasets transformers"
      ],
      "metadata": {
        "id": "59fEiv_Qjhss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch \n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "OeQBSt9Xjhss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавте код для подготовки данных"
      ],
      "metadata": {
        "id": "kSCGiSm0K1Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Слой внимания (2 балла)\n",
        "\n"
      ],
      "metadata": {
        "id": "EIJc9bvH1qMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ниже вам нужно реализовать слой для `MultiheadAttention`.\n",
        "\n"
      ],
      "metadata": {
        "id": "PW_QSr1NsqrJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cPPRwaWB98f"
      },
      "source": [
        "One of the key, novel concepts introduced by the Transformer paper is the *multi-head attention layer*. \n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/transformer-attention.png?raw=1)\n",
        "\n",
        "Attention can be though of as *queries*, *keys* and *values* - where the query is used with the key to get an attention vector (usually the output of a *softmax* operation and has all values between 0 and 1 which sum to 1) which is then used to get a weighted sum of the values.\n",
        "\n",
        "The Transformer uses *scaled dot-product attention*, where the query and key are combined by taking the dot product between them, then applying the softmax operation and scaling by $d_k$ before finally then multiplying by the value. $d_k$ is the *head dimension*, `head_dim`, which we will shortly explain further.\n",
        "\n",
        "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$ \n",
        "\n",
        "This is similar to standard *dot product attention* but is scaled by $d_k$, which the paper states is used to stop the results of the dot products growing large, causing gradients to become too small.\n",
        "\n",
        "However, the scaled dot-product attention isn't simply applied to the queries, keys and values. Instead of doing a single attention application the queries, keys and values have their `hid_dim` split into $h$ *heads* and the scaled dot-product attention is calculated over all heads in parallel. This means instead of paying attention to one concept per attention application, we pay attention to $h$. We then re-combine the heads into their `hid_dim` shape, thus each `hid_dim` is potentially paying attention to $h$ different concepts.\n",
        "\n",
        "$$ \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^O $$\n",
        "\n",
        "$$\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) $$\n",
        "\n",
        "$W^O$ is the linear layer applied at the end of the multi-head attention layer, `fc`. $W^Q, W^K, W^V$ are the linear layers `fc_q`, `fc_k` and `fc_v`.\n",
        "\n",
        "Walking through the module, first we calculate $QW^Q$, $KW^K$ and $VW^V$ with the linear layers, `fc_q`, `fc_k` and `fc_v`, to give us `Q`, `K` and `V`. Next, we split the `hid_dim` of the query, key and value into `n_heads` using `.view` and correctly permute them so they can be multiplied together. We then calculate the `energy` (the un-normalized attention) by multiplying `Q` and `K` together and scaling it by the square root of `head_dim`, which is calulated as `hid_dim // n_heads`. We then mask the energy so we do not pay attention over any elements of the sequeuence we shouldn't, then apply the softmax and dropout. We then apply the attention to the value heads, `V`, before combining the `n_heads` together. Finally, we multiply this $W^O$, represented by `fc_o`. \n",
        "\n",
        "Note that in our implementation the lengths of the keys and values are always the same, thus when matrix multiplying the output of the softmax, `attention`, with `V` we will always have valid dimension sizes for matrix multiplication. This multiplication is carried out using `torch.matmul` which, when both tensors are >2-dimensional, does a batched matrix multiplication over the last two dimensions of each tensor. This will be a **[query len, key len] x [value len, head dim]** batched matrix multiplication over the batch size and each head which provides the **[batch size, n heads, query len, head dim]** result.\n",
        "\n",
        "One thing that looks strange at first is that dropout is applied directly to the attention. This means that our attention vector will most probably not sum to 1 and we may pay full attention to a token but the attention over that token is set to 0 by dropout. This is never explained, or even mentioned, in the paper however is used by the [official implementation](https://github.com/tensorflow/tensor2tensor/) and every Transformer implementation since, [including BERT](https://github.com/google-research/bert/)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PcP-CHNfMwdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, hid_dim, num_heads, attn_dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        \n",
        "        assert hid_dim % num_heads == 0, \"invalid heads and embedding dimension configuration\"\n",
        "        \n",
        "        self.key = nn.Linear(hid_dim, hid_dim)\n",
        "        self.value = nn.Linear(hid_dim, hid_dim)\n",
        "        self.query = nn.Linear(hid_dim, hid_dim)\n",
        "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
        "\n",
        "        self.head_dim = hid_dim // num_heads\n",
        "\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    \n",
        "    #(batch_size, seq_len, embed_dim)\n",
        "    def forward(self, q, k, v, mask):\n",
        "        batch_size = q.size(0)\n",
        "        seq_len = q.size(1)\n",
        "        \n",
        "        # Добавте код для подготовки данных\n",
        "        \n",
        "        return attn, y"
      ],
      "metadata": {
        "id": "mgF5jttMql7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для удобства будем хранить конфигурацию для модели в отдельном классе. "
      ],
      "metadata": {
        "id": "Mm38Cm07te3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    attn_dropout = 0.1\n",
        "    embed_dropout = 0.1\n",
        "    ff_dropout = 0.1\n",
        "    num_heads = 8\n",
        "    num_blocks = 4\n",
        "    embed_dim = 512\n",
        "    \n",
        "    def __init__(\n",
        "        self, vocab_size, max_len, **kwargs\n",
        "    ):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        for key, value in kwargs.items():\n",
        "            setattr(self, key, value)    "
      ],
      "metadata": {
        "id": "NGeUu_T2qOff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #x = [batch size, seq len, hid dim]  \n",
        "        x = self.dropout(self.act(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "EBv0DHPsuqa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.embed_dim\n",
        "        self.ln1 = nn.LayerNorm(embed_dim)\n",
        "        self.ln2 = nn.LayerNorm(embed_dim)\n",
        "        self.attention = MultiheadAttention(embed_dim, config.num_heads, config.attn_dropout)\n",
        "\n",
        "        self.ff = PositionwiseFeedforwardLayer(embed_dim, embed_dim * 4, config.ff_dropout) \n",
        "    \n",
        "    def forward(self, x, mask):\n",
        "        x = self.ln1(x)\n",
        "        \n",
        "        attn, dx = self.attention(x, x, x, mask)\n",
        "\n",
        "        x = x + dx\n",
        "        \n",
        "        x = x + self.ff(self.ln2(x))\n",
        "        return attn, x"
      ],
      "metadata": {
        "id": "baLyrErwqdVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучните модель для генерации тескта (4 балла)"
      ],
      "metadata": {
        "id": "evOAEDppOhsI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S7B9IvovLXid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы не хотим что бы наша модель загдядывала в будущее. Для этого мы создаем масску по которой текущий токен может только смотреть на себя и на предыдушие. Для этого нудна маска у которой элементы над главной диагонялью нулевые. Для этого можно использовать `torch.tril`. \n",
        "Пример мастки для последовательность длинны 5:\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 1\\\\\n",
        "\\end{matrix}$$"
      ],
      "metadata": {
        "id": "Nvf0wZxeNcYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mask(seq):\n",
        "    ... # TODO: Your code here\n",
        "    return mask"
      ],
      "metadata": {
        "id": "JXLU2DiPv_4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополните код для модели"
      ],
      "metadata": {
        "id": "1NlSevlLQNha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.embed_dim\n",
        "        self.max_len = config.max_len\n",
        "        self.tok_embed = \n",
        "        self.pos_embed = nn.Parameter(\n",
        "            torch.zeros(1, config.max_len, embed_dim)\n",
        "        )\n",
        "\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [Block(config) for _ in range(config.num_blocks)]\n",
        "        )\n",
        "        self.ln = nn.LayerNorm(embed_dim)\n",
        "        self.fc = nn.Linear(embed_dim, config.vocab_size)\n",
        "    \n",
        "    def forward(self, token_indexes):\n",
        "        # batch_size = x.size(0)\n",
        "        seq_len = token_indexes.size(1)\n",
        "        assert seq_len <= self.max_len, \"sequence longer than model capacity\"\n",
        "        \n",
        "        tok_embedding = ... # TODO: Your code here\n",
        "\n",
        "        # tok_embedding.shape == (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        pos_embedding = ... # TODO: Your code here\n",
        "\n",
        "        # pos_embedding.shape == (1, seq_len, embed_dim)\n",
        "        \n",
        "        x = self.dropout(tok_embedding + pos_embedding)\n",
        "\n",
        "        seq_len = x.size(1)\n",
        "\n",
        "        mask = make_mask(token_indexes)\n",
        "\n",
        "        # Примените все блоки последовательно\n",
        "        # TODO: Your code here\n",
        "\n",
        "        ...        \n",
        "\n",
        "        x = self.ln(x)\n",
        "        x = self.fc(x)\n",
        "        # x.shape == (batch_size, seq_len, vocab_size)\n",
        "        return attn_list, x"
      ],
      "metadata": {
        "id": "q4CIifvpqRzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izp-AJ-RDtJ9",
        "outputId": "e09fafd0-81e2-423c-d71b-16d7759d1017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tokenizer.vocab_size\n",
        "\n",
        "config = GPTConfig(vocab_size, max_seq_len)\n",
        "model = GPT(config).to(device)"
      ],
      "metadata": {
        "id": "NIp_w8_HqzkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "model(batch[:, :-1].to(device))[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jx1ix8TrLxr",
        "outputId": "fc7a477a-fd76-424c-e7f8-0b07428692d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 256, 8000])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "G-peSCz_NhE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0005\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "9V8oy5i-rSe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(ignore_index = pad_token_idx)"
      ],
      "metadata": {
        "id": "_Alhboqx4emr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Реализуйте обучение, так же как в предущей тетрадке\n",
        "def train_epoch(model, callback):\n",
        "    ...\n"
      ],
      "metadata": {
        "id": "Wo5P_8-15vUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model):\n",
        "    ..."
      ],
      "metadata": {
        "id": "tTAa7iZwJ7JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получите `loss < 4.5 `"
      ],
      "metadata": {
        "id": "HhtCYcITo5uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def callback(train_loss):\n",
        "    eval_loss = eval_model(model)\n",
        "    model.train()\n",
        "    print(f'Epoch: {epoch+1:02} | train_loss = {train_loss:.5f}, eval_loss = {eval_loss:.5f}')\n",
        "\n",
        "for epoch in trange(1):\n",
        "    train_loss = train_epoch(model, callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507,
          "referenced_widgets": [
            "af8a9e7196284adfb38e8d8bd2dadc1d",
            "a97566da2a8b43d3a109fb08ff659898",
            "edfaec824ae148f3b04521edd1e2313b",
            "e8695208c42043aea6efe78793641791",
            "23108a4b1c394dd7bf924a5dfdde7696",
            "6467ecaf87804ce29383a0cf4eee1485",
            "d64360b632b6468dadaf7e974aef5fea",
            "3e1332fb0fd3488ba036e8dee65b7ed2",
            "250331bf8de84ca382e3763ab5bf6da9",
            "48ed39c3eb8748c1a6d7a839304513ba",
            "de15d3d0035841de8e5b704c2dbf0587",
            "258ab1637d0d4fb4a8711c8d36535c7d",
            "2ae9585fad82471c88cf470ce16bb6d6",
            "577a355427ff494a9c324ad9f280d84c",
            "41bd8de5eab543d1a88344d53e39856f",
            "9b9de2067e4d4604a819d738d0899e2e",
            "de7603d3588b43309d15dbc8af5e9c4a",
            "88425460fe344e868b79b1567c38535a",
            "5bda4a67e25d47e39d8964861998bff6",
            "3eb15e972b9b4749b8309ff246f159d5",
            "3e9e93aee32c4249888c2ab4e6bd8448",
            "086defb81412400ea403639cb6b6a7e4"
          ]
        },
        "id": "u53s8iAaHvkx",
        "outputId": "74ca4fec-3304-4271-82a0-e67a89f88ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af8a9e7196284adfb38e8d8bd2dadc1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17133 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "258ab1637d0d4fb4a8711c8d36535c7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | train_loss = 4.44060, eval_loss = 4.41045\n",
            "Epoch: 01 | train_loss = 4.37993, eval_loss = 4.34921\n",
            "Epoch: 01 | train_loss = 4.33095, eval_loss = 4.30364\n",
            "Epoch: 01 | train_loss = 4.28178, eval_loss = 4.27192\n",
            "Epoch: 01 | train_loss = 4.24900, eval_loss = 4.23460\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-a3408e2d19d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-fb9cd431685f>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, callback)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"я помню чудное мгновенье\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Akmq4rxbJb",
        "outputId": "bb0dda30-120b-49d0-8f56-94628aced7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 156, 2769, 2723, 539, 2646, 1881, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def continues_sentence(sentence, model, max_len = 30):\n",
        "    # Возмите код из прошлого задания"
      ],
      "metadata": {
        "id": "nrWzAch9vuYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continues_sentence(\"Я помню чудное мгновенье\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZD6xO9_0w4L6",
        "outputId": "2df55249-607a-4f8f-cc28-220b77ffe1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'я помню чудное мгновенье с ужасным чувством.. он мне думает о каком - то особенном положении : он еще не бывал и снова не было. если начинают головы'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "continues_sentence(\"Мой дядя самых честных правил,\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wMybLhDd4Pc2",
        "outputId": "637cf550-1404-4291-d822-4d00ed3d49f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'мои дядя самых честных правил, законы мои жорея : прежде всякии сказал :, что лютера, без вас же разумнымство останется древним народам'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "continues_sentence(\"Четыре года потратил Деонардо на\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U3bDy6mk_8Jm",
        "outputId": "9cf0f6a2-baec-4067-ae07-7942b8a28922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'четыре года потратил деонардо на другои вопрос с потаевыми классами и, чувствуя от всех на волеи и очень трудно просить рент либеральную типу'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "continues_sentence(\"если крикнет рать святая\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FBiAtkLAADx2",
        "outputId": "18f4d123-2a82-4ac7-ec1f-875db5c8ba51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'если крикнет рать святая жида. собрав фисию владимир, как будто он по самыи заслужен не даст, что, что другого оттенка проска'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "continues_sentence(\"Он пересел на свой стул, придвинул к себе суп, говядину и стал \", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rGdIPEUK0oW3",
        "outputId": "91ad79cb-0d24-4bba-8816-918746f3658d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'он пересел на свои стул, придвинул к себе суп, говядину и стал за ним спокоиности, и настоичивал на нее, всю чаику : \" счастье мне удалось это заключаться в'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подберити варианты количетва блоков и количетсва голов при которых модель дает хороший результат."
      ],
      "metadata": {
        "id": "qcySplxtw7bX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Визуализация внимания"
      ],
      "metadata": {
        "id": "JWosm81qkqfa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IA7D50cSkkMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = list(encode(sentence.lower()))\n",
        "\n",
        "src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "3UjAdkdYoZyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq2uBPUUzQpm",
        "outputId": "54964a91-4f68-4cc5-c601-e57bb3c8c492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn, _ = model(src_tensor)\n"
      ],
      "metadata": {
        "id": "tPNMWjg8p6i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn[0][0, :, -1, :].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NBjinUMrtj8",
        "outputId": "e2299d45-5ff7-42e0-e142-46e873434259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}