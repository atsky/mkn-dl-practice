{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHJJv6Doqxdi"
   },
   "source": [
    "В задании вам понадобится собрать генеративную модлель для языка и спользованием механизма внимания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59fEiv_Qjhss"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet sentencepiece datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeQBSt9Xjhss"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch \n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSCGiSm0K1Es"
   },
   "outputs": [],
   "source": [
    "# Добавте код для подготовки данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIJc9bvH1qMZ"
   },
   "source": [
    "\n",
    "\n",
    "# Слой внимания (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PW_QSr1NsqrJ"
   },
   "source": [
    "Ниже вам нужно реализовать слой для `MultiheadAttention`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cPPRwaWB98f"
   },
   "source": [
    "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/transformer-attention.png?raw=1)\n",
    "\n",
    "Механизм внимания состоит из запросов (*queries*), ключей (*keys*) и значений (*values*) - где запрос используется с ключом для получения вектора внимания (обычно результат операции *softmax* и имеет все значения от 0 до 1, сумма которых равна 1), который затем используется для получения взвешенной суммы значений.\n",
    "\n",
    "Transformer использует *scaled dot-product attention*, где запрос и ключ объединяются путем скалярного произведения между ними, затем применения операции softmax и масштабирования на $d_k$ перед, наконец, умножением на значение. $d_k$ — это *размер головы*, `head_dim`, \n",
    "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$ \n",
    "\n",
    "Это похоже на стандартное *dot product attention*, но масштабируется с помощью $d_k$, который используется для предотвращения увеличения результатов скалярных произведений, что приводит к тому, что градиенты становятся слишком маленькими.\n",
    "\n",
    "Однако *dot product attention* не просто применяется к запросам, ключам и значениям. Вместо того, чтобы делать одно применения внимания, запросы, ключи и значения имеют разделяются $h$ *голов*, и внимание вычисляется для всех головок параллельно. Это означает, что вместо того, чтобы обращать внимание на одну часть последовательности, мы обращаем внимание на $h$. Затем мы обратно объединяем головы в их вектор размерность «hid_dim», таким образом, каждый «hid_dim» потенциально обращает внимание на $h$ разных областей.\n",
    "\n",
    "$$ \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^O $$\n",
    "\n",
    "$$\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) $$\n",
    "\n",
    "$W^O$ линейный слой который применяется в конце слоя, `fc_o`. $W^Q, W^K, W^V$d в модели представлены линейнми слоями `fc_query`, `fc_key` and `fc_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgF5jttMql7e"
   },
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, hid_dim, num_heads, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        assert hid_dim % num_heads == 0, \"invalid heads and embedding dimension configuration\"\n",
    "        \n",
    "        self.fc_key = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_value = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_query = nn.Linear(hid_dim, hid_dim)\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "        self.head_dim = hid_dim // num_heads\n",
    "\n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "    \n",
    "    #(batch_size, seq_len, embed_dim)\n",
    "    def forward(self, q, k, v, mask):\n",
    "        batch_size = q.size(0)\n",
    "        seq_len = q.size(1)\n",
    "        # q.shape, k.shape, v.shape == (batch_size, seq_len, embed_dim)\n",
    "        k_t = self.fc_key(k).reshape(batch_size, seq_len, self.num_heads, self.head_dim).permute(0, 2, 3, 1)\n",
    "        # k_t.shape == (batch_size, num_heads, head_dim, seq_len)\n",
    "\n",
    "        v = self.fc_value(v).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        # v.shape == (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "        q = self.fc_query(q).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        # q.shape == (batch_size, num_heads, seq_len, head_dim)\n",
    "        \n",
    "        \n",
    "        attn = ... # TODO: Your code here\n",
    "        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n",
    "\n",
    "\n",
    "        attn = self.attn_dropout(attn)\n",
    "\n",
    "        y = torch.matmul(attn, v)\n",
    "        # y.shape == (batch_size, num_heads, seq_len, head_dim)\n",
    "        y = y.transpose(1, 2)\n",
    "        # y.shape == (batch_size, seq_len, num_heads, head_dim)\n",
    "        y = y.reshape(batch_size, seq_len, -1)\n",
    "        # y.shape == (batch_size, seq_len, embed_dim)\n",
    "        y = self.fc_o(y)\n",
    "        \n",
    "        return attn, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm38Cm07te3Q"
   },
   "source": [
    "Для удобства будем хранить конфигурацию для модели в отдельном классе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGeUu_T2qOff"
   },
   "outputs": [],
   "source": [
    "class GPTConfig:\n",
    "    attn_dropout = 0.1\n",
    "    embed_dropout = 0.1\n",
    "    ff_dropout = 0.1\n",
    "    num_heads = 4\n",
    "    num_blocks = 2\n",
    "    embed_dim = 512\n",
    "    \n",
    "    def __init__(\n",
    "        self, vocab_size, max_len, **kwargs\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBv0DHPsuqa9"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [batch size, seq len, hid dim]  \n",
    "        x = self.dropout(self.act(self.fc_1(x)))\n",
    "        \n",
    "        #x = [batch size, seq len, pf dim]\n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baLyrErwqdVw"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.embed_dim\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.attention = MultiheadAttention(embed_dim, config.num_heads, config.attn_dropout)\n",
    "\n",
    "        self.ff = PositionwiseFeedforwardLayer(embed_dim, embed_dim * 4, config.ff_dropout) \n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        x = self.ln1(x)\n",
    "        \n",
    "        attn, dx = self.attention(x, x, x, mask)\n",
    "\n",
    "        x = x + dx\n",
    "        \n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return attn, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evOAEDppOhsI"
   },
   "source": [
    "# Обучните модель для генерации тескта (4 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7B9IvovLXid"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nvf0wZxeNcYM"
   },
   "source": [
    "Мы не хотим чтобы наша модель заглядывала в будущее. Для этого мы создаем маску по которой текущий токен может только смотреть на себя и на предыдущие. Для этого нужна маска у которой элементы над главной диагональю нулевые. Для этого можно использовать `torch.tril`. \n",
    "Пример масти для последовательность длины 5:\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 1\\\\\n",
    "\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXLU2DiPv_4g"
   },
   "outputs": [],
   "source": [
    "def make_mask(seq):\n",
    "    ... # TODO: Your code here\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NlSevlLQNha"
   },
   "source": [
    "Дополните код для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4CIifvpqRzB"
   },
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.embed_dim\n",
    "        self.max_len = config.max_len\n",
    "        self.tok_embed = \n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.zeros(1, config.max_len, embed_dim)\n",
    "        )\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(config) for _ in range(config.num_blocks)]\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, config.vocab_size)\n",
    "    \n",
    "    def forward(self, token_indexes):\n",
    "        # batch_size = x.size(0)\n",
    "        seq_len = token_indexes.size(1)\n",
    "        assert seq_len <= self.max_len, \"sequence longer than model capacity\"\n",
    "        \n",
    "        tok_embedding = ... # TODO: Your code here\n",
    "\n",
    "        # tok_embedding.shape == (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        pos_embedding = ... # TODO: Your code here\n",
    "\n",
    "        # pos_embedding.shape == (1, seq_len, embed_dim)\n",
    "        \n",
    "        x = self.dropout(tok_embedding + pos_embedding)\n",
    "\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        mask = make_mask(token_indexes)\n",
    "\n",
    "        # Примените все блоки последовательно\n",
    "        # TODO: Your code here\n",
    "\n",
    "        ...        \n",
    "\n",
    "        x = self.ln(x)\n",
    "        x = self.fc(x)\n",
    "        # x.shape == (batch_size, seq_len, vocab_size)\n",
    "        return attn_list, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izp-AJ-RDtJ9",
    "outputId": "e09fafd0-81e2-423c-d71b-16d7759d1017"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIp_w8_HqzkK"
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "config = GPTConfig(vocab_size, max_seq_len)\n",
    "model = GPT(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Jx1ix8TrLxr",
    "outputId": "fc7a477a-fd76-424c-e7f8-0b07428692d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 8000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "model(batch[:, :-1].to(device))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-peSCz_NhE7"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9V8oy5i-rSe2"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Alhboqx4emr"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index = pad_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wo5P_8-15vUR"
   },
   "outputs": [],
   "source": [
    "# Реализуйте обучение, так же как в предущей тетрадке\n",
    "def train_epoch(model, callback):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTAa7iZwJ7JK"
   },
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhtCYcITo5uG"
   },
   "source": [
    "Подберити варианты количетва блоков и количетсва голов при которых модель дает хороший результат. \n",
    "Получите `loss < 4.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507,
     "referenced_widgets": [
      "af8a9e7196284adfb38e8d8bd2dadc1d",
      "a97566da2a8b43d3a109fb08ff659898",
      "edfaec824ae148f3b04521edd1e2313b",
      "e8695208c42043aea6efe78793641791",
      "23108a4b1c394dd7bf924a5dfdde7696",
      "6467ecaf87804ce29383a0cf4eee1485",
      "d64360b632b6468dadaf7e974aef5fea",
      "3e1332fb0fd3488ba036e8dee65b7ed2",
      "250331bf8de84ca382e3763ab5bf6da9",
      "48ed39c3eb8748c1a6d7a839304513ba",
      "de15d3d0035841de8e5b704c2dbf0587",
      "258ab1637d0d4fb4a8711c8d36535c7d",
      "2ae9585fad82471c88cf470ce16bb6d6",
      "577a355427ff494a9c324ad9f280d84c",
      "41bd8de5eab543d1a88344d53e39856f",
      "9b9de2067e4d4604a819d738d0899e2e",
      "de7603d3588b43309d15dbc8af5e9c4a",
      "88425460fe344e868b79b1567c38535a",
      "5bda4a67e25d47e39d8964861998bff6",
      "3eb15e972b9b4749b8309ff246f159d5",
      "3e9e93aee32c4249888c2ab4e6bd8448",
      "086defb81412400ea403639cb6b6a7e4"
     ]
    },
    "id": "u53s8iAaHvkx",
    "outputId": "74ca4fec-3304-4271-82a0-e67a89f88ea9"
   },
   "outputs": [],
   "source": [
    "def callback(train_loss):\n",
    "    eval_loss = eval_model(model)\n",
    "    model.train()\n",
    "    print(f'Epoch: {epoch+1:02} | train_loss = {train_loss:.5f}, eval_loss = {eval_loss:.5f}')\n",
    "\n",
    "for epoch in trange(1):\n",
    "    train_loss = train_epoch(model, callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54Akmq4rxbJb",
    "outputId": "bb0dda30-120b-49d0-8f56-94628aced7ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 156, 2769, 2723, 539, 2646, 1881, 3]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"я помню чудное мгновенье\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nrWzAch9vuYd"
   },
   "outputs": [],
   "source": [
    "def continues_sentence(sentence, model, max_len = 30):\n",
    "    # Возмите код из прошлого задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZD6xO9_0w4L6",
    "outputId": "2df55249-607a-4f8f-cc28-220b77ffe1d1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'я помню чудное мгновенье с ужасным чувством.. он мне думает о каком - то особенном положении : он еще не бывал и снова не было. если начинают головы'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"Я помню чудное мгновенье\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wMybLhDd4Pc2",
    "outputId": "637cf550-1404-4291-d822-4d00ed3d49f3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'мои дядя самых честных правил, законы мои жорея : прежде всякии сказал :, что лютера, без вас же разумнымство останется древним народам'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"Мой дядя самых честных правил,\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "U3bDy6mk_8Jm",
    "outputId": "9cf0f6a2-baec-4067-ae07-7942b8a28922"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'четыре года потратил деонардо на другои вопрос с потаевыми классами и, чувствуя от всех на волеи и очень трудно просить рент либеральную типу'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"Четыре года потратил Деонардо на\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FBiAtkLAADx2",
    "outputId": "18f4d123-2a82-4ac7-ec1f-875db5c8ba51"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'если крикнет рать святая жида. собрав фисию владимир, как будто он по самыи заслужен не даст, что, что другого оттенка проска'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"если крикнет рать святая\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rGdIPEUK0oW3",
    "outputId": "91ad79cb-0d24-4bba-8816-918746f3658d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'он пересел на свои стул, придвинул к себе суп, говядину и стал за ним спокоиности, и настоичивал на нее, всю чаику : \" счастье мне удалось это заключаться в'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"Он пересел на свой стул, придвинул к себе суп, говядину и стал \", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcySplxtw7bX"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "JWosm81qkqfa"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "086defb81412400ea403639cb6b6a7e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23108a4b1c394dd7bf924a5dfdde7696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "250331bf8de84ca382e3763ab5bf6da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "258ab1637d0d4fb4a8711c8d36535c7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ae9585fad82471c88cf470ce16bb6d6",
       "IPY_MODEL_577a355427ff494a9c324ad9f280d84c",
       "IPY_MODEL_41bd8de5eab543d1a88344d53e39856f"
      ],
      "layout": "IPY_MODEL_9b9de2067e4d4604a819d738d0899e2e"
     }
    },
    "2ae9585fad82471c88cf470ce16bb6d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de7603d3588b43309d15dbc8af5e9c4a",
      "placeholder": "​",
      "style": "IPY_MODEL_88425460fe344e868b79b1567c38535a",
      "value": " 15%"
     }
    },
    "3e1332fb0fd3488ba036e8dee65b7ed2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e9e93aee32c4249888c2ab4e6bd8448": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3eb15e972b9b4749b8309ff246f159d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "41bd8de5eab543d1a88344d53e39856f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e9e93aee32c4249888c2ab4e6bd8448",
      "placeholder": "​",
      "style": "IPY_MODEL_086defb81412400ea403639cb6b6a7e4",
      "value": " 2548/17133 [20:07&lt;1:50:56,  2.19it/s]"
     }
    },
    "48ed39c3eb8748c1a6d7a839304513ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "577a355427ff494a9c324ad9f280d84c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bda4a67e25d47e39d8964861998bff6",
      "max": 17133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3eb15e972b9b4749b8309ff246f159d5",
      "value": 2548
     }
    },
    "5bda4a67e25d47e39d8964861998bff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6467ecaf87804ce29383a0cf4eee1485": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88425460fe344e868b79b1567c38535a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b9de2067e4d4604a819d738d0899e2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a97566da2a8b43d3a109fb08ff659898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6467ecaf87804ce29383a0cf4eee1485",
      "placeholder": "​",
      "style": "IPY_MODEL_d64360b632b6468dadaf7e974aef5fea",
      "value": "  0%"
     }
    },
    "af8a9e7196284adfb38e8d8bd2dadc1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a97566da2a8b43d3a109fb08ff659898",
       "IPY_MODEL_edfaec824ae148f3b04521edd1e2313b",
       "IPY_MODEL_e8695208c42043aea6efe78793641791"
      ],
      "layout": "IPY_MODEL_23108a4b1c394dd7bf924a5dfdde7696"
     }
    },
    "d64360b632b6468dadaf7e974aef5fea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de15d3d0035841de8e5b704c2dbf0587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de7603d3588b43309d15dbc8af5e9c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8695208c42043aea6efe78793641791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48ed39c3eb8748c1a6d7a839304513ba",
      "placeholder": "​",
      "style": "IPY_MODEL_de15d3d0035841de8e5b704c2dbf0587",
      "value": " 0/1 [20:07&lt;?, ?it/s]"
     }
    },
    "edfaec824ae148f3b04521edd1e2313b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e1332fb0fd3488ba036e8dee65b7ed2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_250331bf8de84ca382e3763ab5bf6da9",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
